{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of UI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVuSNJDKuFPE",
        "outputId": "3da0cf42-d8a0-4b99-f4f2-5802e2a16f9f"
      },
      "source": [
        "#Install ngrok for flask based web app\n",
        "!pip install flask-ngrok\n",
        "#Mounting Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI0PVEZS4SLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8223cd5-d46f-42fa-864e-d12cb1eb0814"
      },
      "source": [
        "#Importing Required Modules\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import imutils\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import math\n",
        "from tensorflow.keras.preprocessing import image as IMAGE\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils import face_utils\n",
        "import dlib\n",
        "import keras\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask\n",
        "from flask import render_template, request, jsonify\n",
        "from sklearn.metrics import accuracy_score\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "#Face Detection Model Initialization\n",
        "prototxt = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/models/deploy.prototxt'\n",
        "dnn_path = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/models/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "face_detection_model = cv2.dnn.readNetFromCaffe(prototxt, dnn_path)\n",
        "\n",
        "#Facial Landmarks Detector Model\n",
        "model_path = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/models/shape_predictor_5_face_landmarks.dat'\n",
        "predictor = dlib.shape_predictor(model_path)\n",
        "\n",
        "#Path for directories from the Database\n",
        "train_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/trainset'\n",
        "roi_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/roiset'\n",
        "clahe_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/claheset'\n",
        "test_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/testset'\n",
        "aug_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/augmentset'\n",
        "test_roi_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/testroiset'\n",
        "test_clahe_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/testclaheset'\n",
        "val_dir = '/content/drive/My Drive/Periocular_Recognition/Code/dataset1/valset'\n",
        "\n",
        "#Test Subjects Names\n",
        "people_in_db = {\n",
        "  \"ben_afflek\": \"Ben Afflek\",\n",
        "  \"madonna\": \"Madonna\",\n",
        "  \"mindy_kaling\": \"Mindy Kaling\",\n",
        "  \"jerry_seinfeld\": \"Jerry Sienfield\" \n",
        "}\n",
        "\n",
        "#a and b values for changing extent of region of interest\n",
        "a = 1.25\n",
        "b = 0.95\n",
        "\n",
        "#Augementor for expanding training Data\n",
        "augmentor = ImageDataGenerator(\n",
        "\t\trotation_range=20,\n",
        "\t\twidth_shift_range=0.2,\n",
        "\t\theight_shift_range=0.2,\n",
        "\t\tshear_range=0.15,\n",
        "\t\tvertical_flip=True,\n",
        "    brightness_range=[0.5,1.5],\n",
        "    zoom_range = 0.3, \n",
        "\t\tfill_mode=\"nearest\")\n",
        "\n",
        "#VGG16 Feature extractor\n",
        "vggmodel = VGG16(weights='imagenet', include_top=False)\n",
        "#KNN Classifiers\n",
        "left_model = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "right_model = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "#Dictionaries to calculate avg sum of recognition probabilities\n",
        "classes_prob_left = {}\n",
        "classes_prob_right = {}\n",
        "avg_prob = {}\n",
        "\n",
        "def augmentation(train_dir):\n",
        "  temp = 0\n",
        "  for person in os.listdir(train_dir):\n",
        "    person_dir = os.path.join(train_dir, person)\n",
        "    save_dir = os.path.join(aug_dir,person)\n",
        "    for img in os.listdir(person_dir):\n",
        "      print(\"augmentation on \" + person)\n",
        "      img_path=os.path.join(person_dir, img)\n",
        "      to_augment = load_img(img_path)\n",
        "      to_augment = img_to_array(to_augment)\n",
        "      to_augment = np.expand_dims(to_augment, axis=0)\n",
        "      total_images = 0\n",
        "      generator = augmentor.flow(to_augment, batch_size=1, save_to_dir=save_dir, save_prefix=person, save_format=\"jpg\")\n",
        "      for to_augment in generator:\n",
        "\t      total_images += 1\n",
        "\t      if total_images == 10:\n",
        "\t\t      break\n",
        "  print(\"STEP 1: DATA AUGMENTATION DONE !!!\")\n",
        "\n",
        "#Detect Face region using DNN\n",
        "def get_face(image, model):\n",
        "  h, w = image.shape[:2]\n",
        "  blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "  model.setInput(blob)\n",
        "  detected_face = model.forward()\n",
        "  for i in range(detected_face.shape[2]):\n",
        "    confidence = detected_face[0, 0, i, 2]\n",
        "    if confidence > 0.5:\n",
        "      box = detected_face[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "      (x, y, x1, y1) = box.astype(\"int\")\n",
        "      face = [x, y, x1, y1]\n",
        "    return face\n",
        "\n",
        "#Convert face region bounding box to square for consistency\n",
        "def get_square_face(image, face):\n",
        "  offset = int(abs((face[3] - face[1]) * 0.1))\n",
        "  offset_arr = [0, offset]\n",
        "  left_x = face[0] + offset_arr[0]\n",
        "  top_y = face[1] + offset_arr[1]\n",
        "  right_x = face[2] + offset_arr[0]\n",
        "  bottom_y = face[3] + offset_arr[1]\n",
        "  shifted_box = [left_x, top_y, right_x, bottom_y]\n",
        "  bb_width = right_x - left_x\n",
        "  bb_height = bottom_y - top_y\n",
        "  diff = bb_height - bb_width\n",
        "  delta = int(abs(diff) / 2)\n",
        "  if diff == 0:\n",
        "    pass\n",
        "  elif diff > 0:\n",
        "    left_x -= delta\n",
        "    right_x += delta\n",
        "    if diff % 2 == 1:\n",
        "      right_x += 1\n",
        "  else:\n",
        "    top_y -= delta\n",
        "    bottom_y += delta\n",
        "    if diff % 2 == 1:\n",
        "      bottom_y += 1\n",
        "  assert ((right_x - left_x) == (bottom_y - top_y)), 'Box is not square.'\n",
        "  facebox = [left_x, top_y, right_x, bottom_y]\n",
        "  h, w = image.shape[:2]\n",
        "  if facebox[0] < 0:\n",
        "    facebox[0] = 0\n",
        "  if facebox[1] < 0:\n",
        "    facebox[1] = 0\n",
        "  if facebox[2] > w:\n",
        "    facebox[2] = w\n",
        "  if facebox[3] > h:\n",
        "    facebox[3] = h\n",
        "  face_img = image[facebox[1]: facebox[3], facebox[0]: facebox[2]]\n",
        "  face_img = cv2.resize(face_img, (128, 128))\n",
        "  face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
        "  return facebox\n",
        "\n",
        "def euclidean_dist(x, y):\n",
        "  distance = 0.0\n",
        "  for i in range(len(x)-1):\n",
        "    distance += (abs(x[i] - y[i]))**2\n",
        "  return math.sqrt(distance)\n",
        "\n",
        "def roi_extraction(directory):\n",
        "  l_outer = 37\n",
        "  l_inner = 40\n",
        "  r_outer = 46\n",
        "  r_inner = 43\n",
        "  canthus_attr=[37,40,43,46]\n",
        "  person_id = 1\n",
        "  total_people = 24\n",
        "  for person in os.listdir(directory):\n",
        "    person_dir = os.path.join(directory, person)\n",
        "    print(str(person_id) + \" of \" + str(total_people) + \": PERFORMING ROI EXTRACTION ON\", people_in_db[person])\n",
        "    for picture in os.listdir(person_dir):\n",
        "      img_path=os.path.join(person_dir, picture)\n",
        "      img = cv2.imread(img_path)\n",
        "      img = imutils.resize(img, width=400)\n",
        "      img_copy = img.copy()\n",
        "      img_copy2 = img.copy()\n",
        "      img_copy3 = img.copy()\n",
        "      face = get_face(img, face_detection_model)\n",
        "      facebox = get_square_face(img, face)\n",
        "      #cv2.rectangle(img_copy, (facebox[0], facebox[1]),(facebox[2],facebox[3]), (0,0,255),2)\n",
        "      #print(\"DETECTED FACE REGION\\n\")\n",
        "      #cv2_imshow(img_copy)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      facebox = dlib.rectangle(facebox[0],facebox[1],facebox[2],facebox[3])\n",
        "      shape = predictor(img, facebox)\n",
        "      shape = face_utils.shape_to_np(shape)\n",
        "      for (i, (x, y)) in enumerate(shape):\n",
        "        if i == 4 :\n",
        "          pass\n",
        "        else:\n",
        "          cv2.circle(img_copy2, (x, y), 1, (0, 0, 255), 2)\n",
        "      #print(\"DETECTED FACIAL LANDMARKS\")\n",
        "      #cv2_imshow(img_copy2)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      D_left = euclidean_dist(shape[3], shape[2])\n",
        "      D_right = euclidean_dist(shape[0], shape[1])\n",
        "      Lpx = (shape[2][0] + shape[3][0])/2\n",
        "      Lpy = (shape[2][1] + shape[3][1])/2\n",
        "      Rpx = (shape[0][0] + shape[1][0])/2\n",
        "      Rpy = (shape[0][1] + shape[1][1])/2\n",
        "      tlc_left = (int(Lpx - a * D_left) , int(Lpy - b * D_left))\n",
        "      brc_left = (int(Lpx + a * D_left) , int(Lpy + b * D_left))\n",
        "      tlc_right = (int(Rpx - a * D_right) , int(Rpy - b * D_right))\n",
        "      brc_right = (int(Rpx + a * D_right) , int(Rpy + b * D_right))\n",
        "      cv2.rectangle(img_copy3, tlc_left, brc_left, (0, 255, 0), 2)\n",
        "      cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "      #cv2.rectangle(img_copy3, tlc_right, brc_right, (0, 255, 0), 2)\n",
        "      #print(\"DETECTED PERIOCULAR REGIONS\")\n",
        "      #cv2_imshow(img_copy3)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      cropped_right = img[tlc_right[1]:brc_right[1], tlc_right[0]:brc_right[0]]\n",
        "      cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "      #print(\"CROPPED PERIOCULAR REGIONS\")\n",
        "      #cv2_imshow(cropped_right)\n",
        "      #cv2_imshow(cropped_left)\n",
        "      #print(\"\\n\\n\\n\")\n",
        "      cropped_name_left = \"left_\" + picture\n",
        "      cropped_name_right = \"right_\" + picture\n",
        "      cropped_path = os.path.join(roi_dir, person)\n",
        "      cropped_path_left = os.path.join(cropped_path, \"left\")\n",
        "      cropped_path_right = os.path.join(cropped_path, \"right\")\n",
        "      cropped_path_left = os.path.join(cropped_path_left, cropped_name_left)\n",
        "      cropped_path_right = os.path.join(cropped_path_right, cropped_name_right)\n",
        "      #print(cropped_path_left, cropped_path_right)\n",
        "      cv2.imwrite (cropped_path_left, cropped_left)\n",
        "      cv2.imwrite (cropped_path_right, cropped_right)\n",
        "    person_id+=1      \n",
        "  print(\"STEP 1 of 3: ROI EXTRACTION COMPLETED\\n\")\n",
        "\n",
        "def clahe_eye(directory, left_right, person):\n",
        "  for picture in os.listdir(directory):\n",
        "    img_path=os.path.join(directory, picture)\n",
        "    img = cv2.imread(img_path)\n",
        "    #cv2_imshow(picture)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h,s,v = cv2.split(hsv)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4, 4))\n",
        "    v = clahe.apply(v)\n",
        "    hsv = cv2.merge([h,s,v])\n",
        "    clahe_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    #print(\"CLAHE PERFORMED\\n\")\n",
        "    #cv2_imshow(clahe_image)\n",
        "    #print(\"\\n\\n\\n\")\n",
        "    clahe_name = 'clahe_' + picture\n",
        "    clahe_path = os.path.join(clahe_dir, person)\n",
        "    if left_right == 0:\n",
        "      clahe_path = os.path.join(clahe_path,\"left\")\n",
        "    else:\n",
        "      clahe_path = os.path.join(clahe_path,\"right\")\n",
        "    clahe_path = os.path.join(clahe_path,clahe_name)\n",
        "    #print(clahe_path)\n",
        "    cv2.imwrite(clahe_path,clahe_image)\n",
        "\n",
        "def clahe_preprocessing(directory):\n",
        "  person_id = 1\n",
        "  total_people = 24\n",
        "  for person in os.listdir(directory):\n",
        "    print(str(person_id) + \" of \" + str(total_people) + \": PERFORMING CLAHE PRE-PROCESSING ON\", people_in_db[person])\n",
        "    person_dir = os.path.join(roi_dir, person)\n",
        "    person_dir_left = os.path.join(person_dir, \"left\")\n",
        "    person_dir_right = os.path.join(person_dir, \"right\")\n",
        "    clahe_eye(person_dir_left, 0, person)\n",
        "    clahe_eye(person_dir_right, 1, person)\n",
        "    person_id+=1\n",
        "  print(\"STEP 2 of 3: CLAHE PRE-PROCESSING COMPLETED\")\n",
        "\n",
        "def train_classifier():\n",
        "  all_features_left = []\n",
        "  all_features_right = []\n",
        "  labels_left = []\n",
        "  labels_right = []\n",
        "  person_id = 1\n",
        "  total_people = 24\n",
        "  for person in os.listdir(clahe_dir):\n",
        "    print(str(person_id) + \" of \" + str(total_people) + \": TRAINING ON\", people_in_db[person])\n",
        "    person_dir = os.path.join(clahe_dir, person)\n",
        "    person_dir_left = os.path.join(person_dir, \"left\")\n",
        "    person_dir_right = os.path.join(person_dir, \"right\")\n",
        "    for picture in os.listdir(person_dir_left):\n",
        "      label = person + \"_left\"\n",
        "      img_path=os.path.join(person_dir_left, picture)\n",
        "      #print(img_path)\n",
        "      img = IMAGE.load_img(img_path, target_size=(224, 224))\n",
        "      img_arr = IMAGE.img_to_array(img)\n",
        "      img_arr = np.expand_dims(img_arr, axis=0)\n",
        "      img_arr = preprocess_input(img_arr)\n",
        "      feature_vector = vggmodel.predict(img_arr)\n",
        "      #print(features)\n",
        "      vgg16_feature_np = np.array(feature_vector)\n",
        "      vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "      all_features_left.append(vgg16_feature_np)\n",
        "      labels_left.append(label)\n",
        "    for picture in os.listdir(person_dir_right):\n",
        "      label = person + \"_right\"\n",
        "      img_path=os.path.join(person_dir_right, picture)\n",
        "      #print(img_path)\n",
        "      img = IMAGE.load_img(img_path, target_size=(224, 224))\n",
        "      img_arr = IMAGE.img_to_array(img)\n",
        "      img_arr = np.expand_dims(img_arr, axis=0)\n",
        "      img_arr = preprocess_input(img_arr)\n",
        "      feature_vector = vggmodel.predict(img_arr)\n",
        "      #print(features)\n",
        "      vgg16_feature_np = np.array(feature_vector)\n",
        "      vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "      all_features_right.append(vgg16_feature_np)\n",
        "      labels_right.append(label)\n",
        "    person_id+=1\n",
        "  left_model.fit(all_features_left, labels_left)\n",
        "  right_model.fit(all_features_right, labels_right)\n",
        "  print(\"STEP 3 of 3: TRAINING MODEL COMPLETED\")\n",
        "\n",
        "def create_model():\n",
        "  roi_extraction(train_dir)\n",
        "  clahe_preprocessing(roi_dir)\n",
        "  train_classifier()\n",
        "  pickle.dump(left_model, open('/content/drive/My Drive/Periocular_Recognition/Code/dataset1/models/left.sav', 'wb'))\n",
        "  pickle.dump(right_model, open('/content/drive/My Drive/Periocular_Recognition/Code/dataset1/models/right.sav', 'wb'))\n",
        "  return \"done\"\n",
        "\n",
        "def roi_extraction_test(img_path):\n",
        "  picture = \"1.jpg\"\n",
        "  l_outer = 37\n",
        "  l_inner = 40\n",
        "  r_outer = 46\n",
        "  r_inner = 43\n",
        "  canthus_attr=[37,40,43,46]\n",
        "  img = cv2.imread(img_path)\n",
        "  img = imutils.resize(img, width=400)\n",
        "  #cv2_imshow(img)\n",
        "  img_copy = img.copy()\n",
        "  img_copy2 = img.copy()\n",
        "  img_copy3 = img.copy()\n",
        "  face = get_face(img, face_detection_model)\n",
        "  print(face)\n",
        "  if face == None:\n",
        "    print(\"NO FACE SEEN\")\n",
        "  facebox = get_square_face(img, face)\n",
        "  cv2.rectangle(img_copy, (facebox[0], facebox[1]),(facebox[2],facebox[3]), (0,0,255),2)\n",
        "  print(\"DETECTED FACE REGION\\n\")\n",
        "  cv2_imshow(img_copy)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  facebox = dlib.rectangle(facebox[0],facebox[1],facebox[2],facebox[3])\n",
        "  shape = predictor(img, facebox)\n",
        "  shape = face_utils.shape_to_np(shape)\n",
        "  for (i, (x, y)) in enumerate(shape):\n",
        "    if i == 4 :\n",
        "      pass\n",
        "    else:\n",
        "      cv2.circle(img_copy, (x, y), 1, (0, 0, 255), 2)\n",
        "  print(\"DETECTED FACIAL LANDMARKS\")\n",
        "  cv2_imshow(img_copy2)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  D_left = euclidean_dist(shape[3], shape[2])\n",
        "  D_right = euclidean_dist(shape[0], shape[1])\n",
        "  Lpx = (shape[2][0] + shape[3][0])/2\n",
        "  Lpy = (shape[2][1] + shape[3][1])/2\n",
        "  Rpx = (shape[0][0] + shape[1][0])/2\n",
        "  Rpy = (shape[0][1] + shape[1][1])/2\n",
        "  tlc_left = (int(Lpx - a * D_left) , int(Lpy - b * D_left))\n",
        "  brc_left = (int(Lpx + a * D_left) , int(Lpy + b * D_left))\n",
        "  tlc_right = (int(Rpx - a * D_right) , int(Rpy - b * D_right))\n",
        "  brc_right = (int(Rpx + a * D_right) , int(Rpy + b * D_right))\n",
        "  cv2.rectangle(img_copy3, tlc_left, brc_left, (0, 255, 0), 2)\n",
        "  cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "  cv2.rectangle(img_copy3, tlc_right, brc_right, (0, 255, 0), 2)\n",
        "  print(\"DETECTED PERIOCULAR REGIONS\")\n",
        "  cv2_imshow(img_copy3)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  #cv2_imshow(img_copy2)\n",
        "  cropped_right = img[tlc_right[1]:brc_right[1], tlc_right[0]:brc_right[0]]\n",
        "  cropped_left = img[tlc_left[1]:brc_left[1], tlc_left[0]:brc_left[0]]\n",
        "  print(\"CROPPED PERIOCULAR REGIONS\")\n",
        "  cv2_imshow(cropped_right)\n",
        "  cv2_imshow(cropped_left)\n",
        "  print(\"\\n\\n\\n\")\n",
        "  cropped_name_left = \"left_test_\" + picture\n",
        "  cropped_name_right = \"right_test_\" + picture\n",
        "  cropped_path = test_roi_dir\n",
        "  cropped_path_left = os.path.join(cropped_path, \"left\")\n",
        "  cropped_path_right = os.path.join(cropped_path, \"right\")\n",
        "  cropped_path_left = os.path.join(cropped_path_left, cropped_name_left)\n",
        "  cropped_path_right = os.path.join(cropped_path_right, cropped_name_right)\n",
        "  #print(cropped_path_left, cropped_path_right)\n",
        "  cv2.imwrite (cropped_path_left, cropped_left)\n",
        "  cv2.imwrite (cropped_path_right, cropped_right)\n",
        "\n",
        "def clahe_eye_test(directory, left_right):\n",
        "  for picture in os.listdir(directory):\n",
        "    img_path=os.path.join(directory, picture)\n",
        "    img = cv2.imread(img_path)\n",
        "    #cv2_imshow(picture)\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h,s,v = cv2.split(hsv)\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(4, 4))\n",
        "    v = clahe.apply(v)\n",
        "    hsv = cv2.merge([h,s,v])\n",
        "    clahe_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "    print(\"CLAHE PERFORMED\\n\")\n",
        "    cv2_imshow(clahe_image)\n",
        "    print(\"\\n\\n\\n\")\n",
        "    #cv2_imshow(clahe_image)\n",
        "    clahe_name = 'testclahe_' + picture\n",
        "    clahe_path = test_clahe_dir\n",
        "    if left_right == 0:\n",
        "      clahe_path = os.path.join(clahe_path,\"left\")\n",
        "    else:\n",
        "      clahe_path = os.path.join(clahe_path,\"right\")\n",
        "    clahe_path = os.path.join(clahe_path,clahe_name)\n",
        "    #print(clahe_path)\n",
        "    cv2.imwrite(clahe_path,clahe_image)\n",
        "\n",
        "def clahe_preprocessing_test(directory):\n",
        "    test_dir_left = os.path.join(directory, \"left\")\n",
        "    test_dir_right = os.path.join(directory, \"right\")\n",
        "    clahe_eye_test(test_dir_left, 0)\n",
        "    clahe_eye_test(test_dir_right, 1)\n",
        "\n",
        "def predict_person(img_path):\n",
        "  loaded_left = pickle.load(open('/content/drive/My Drive/Periocular_Recognition/Code/dataset1/models/left.sav', 'rb'))\n",
        "  loaded_right = pickle.load(open('/content/drive/My Drive/Periocular_Recognition/Code/dataset1/models/right.sav', 'rb'))\n",
        "  roi_extraction_test(img_path)\n",
        "  clahe_preprocessing_test(test_roi_dir)\n",
        "  test_clahe_dir_left = os.path.join(test_clahe_dir, \"left\")\n",
        "  test_clahe_dir_right = os.path.join(test_clahe_dir, \"right\")\n",
        "  for pic in os.listdir(test_clahe_dir_left):\n",
        "    left_eye_path = os.path.join(test_clahe_dir_left, pic)\n",
        "    left_eye = IMAGE.load_img(left_eye_path, target_size=(224, 224))\n",
        "    img_arr = IMAGE.img_to_array(left_eye)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    img_arr = preprocess_input(img_arr)\n",
        "    feature_vec = vggmodel.predict(img_arr)\n",
        "    vgg16_feature_np = np.array(feature_vec)\n",
        "    vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "    rec_left = loaded_left.predict([vgg16_feature_np])\n",
        "    p_pred_left = loaded_left.predict_proba([vgg16_feature_np])\n",
        "    #print(rec_left, p_pred_left)\n",
        "    rec_left = rec_left.tolist()\n",
        "    rec_left = rec_left[0]\n",
        "    person_left = rec_left.replace(\"_left\", \"\")\n",
        "    #print(person_left)\n",
        "  for pic in os.listdir(test_clahe_dir_right):\n",
        "    right_eye_path = os.path.join(test_clahe_dir_right, pic)\n",
        "    right_eye = IMAGE.load_img(right_eye_path, target_size=(224, 224))\n",
        "    img_arr = IMAGE.img_to_array(right_eye)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)\n",
        "    img_arr = preprocess_input(img_arr)\n",
        "    feature_vec = vggmodel.predict(img_arr)\n",
        "    vgg16_feature_np = np.array(feature_vec)\n",
        "    vgg16_feature_np = vgg16_feature_np.flatten()\n",
        "    rec_right = loaded_right.predict([vgg16_feature_np])\n",
        "    p_pred_right = loaded_right.predict_proba([vgg16_feature_np])\n",
        "    rec_right = rec_right.tolist()\n",
        "    rec_right = rec_right[0]\n",
        "    person_right = rec_right.replace(\"_right\", \"\")\n",
        "    #print(person_right)\n",
        "    #print(rec_right, p_pred_right)\n",
        "  if (person_right == person_left) :\n",
        "    predicted = people_in_db[person_left]\n",
        "    return predicted\n",
        "    #print(\"This is\", people_in_db[person_left])\n",
        "  else :\n",
        "    right_classes = loaded_right.classes_\n",
        "    left_classes = loaded_left.classes_\n",
        "    i = 0\n",
        "    for label in left_classes:\n",
        "      label = label.replace(\"_left\", \"\")\n",
        "      classes_prob_left[label]=p_pred_left[0][i]\n",
        "      i+=1\n",
        "    #print(\"prob left\", classes_prob_left)\n",
        "    i = 0\n",
        "    for label in right_classes:\n",
        "      label = label.replace(\"_right\", \"\")\n",
        "      classes_prob_right[label]=p_pred_right[0][i]\n",
        "      i+=1\n",
        "    #print(\"prob_right\", classes_prob_right)\n",
        "    for pred_label in classes_prob_left:\n",
        "      avg_probability = (classes_prob_left[pred_label] + classes_prob_right[pred_label])/2\n",
        "      avg_prob[pred_label] = avg_probability\n",
        "    #print(\"avg\", avg_prob)\n",
        "    predicted = max(avg_prob, key=avg_prob.get)\n",
        "    predicted = people_in_db[predicted]\n",
        "    return predicted\n",
        "\n",
        "def get_model_accuracy():\n",
        "  true_labels=[]\n",
        "  pred_labels=[]\n",
        "  for person in os.listdir(val_dir):\n",
        "    person_dir = os.path.join(val_dir, person)\n",
        "    for pic in os.listdir(person_dir):\n",
        "      true_labels.append(people_in_db[person])\n",
        "      path = os.path.join(person_dir, pic)\n",
        "      print(person, pic)\n",
        "      predicted_person = predict_person(path)\n",
        "      pred_labels.append(predicted_person)\n",
        "      img = cv2.imread(path)\n",
        "      img = imutils.resize(img, width=100)\n",
        "      print(predicted_person + \"\\n\")\n",
        "      #cv2_imshow(img)\n",
        "      #print(true_labels)\n",
        "      #print(pred_labels)\n",
        "  #print(accuracy_score(true_labels, pred_labels) * 100, \"%\")\n",
        "  return (accuracy_score(true_labels, pred_label) * 100)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "QrVC1lwIMCc4",
        "outputId": "83133746-adbb-4906-f8b6-9e2cab484497"
      },
      "source": [
        "create_model()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of 24: PERFORMING ROI EXTRACTION ON Jerry Sienfield\n",
            "2 of 24: PERFORMING ROI EXTRACTION ON Ben Afflek\n",
            "3 of 24: PERFORMING ROI EXTRACTION ON Mindy Kaling\n",
            "4 of 24: PERFORMING ROI EXTRACTION ON Madonna\n",
            "STEP 1 of 3: ROI EXTRACTION COMPLETED\n",
            "\n",
            "1 of 24: PERFORMING CLAHE PRE-PROCESSING ON Madonna\n",
            "2 of 24: PERFORMING CLAHE PRE-PROCESSING ON Jerry Sienfield\n",
            "3 of 24: PERFORMING CLAHE PRE-PROCESSING ON Ben Afflek\n",
            "4 of 24: PERFORMING CLAHE PRE-PROCESSING ON Mindy Kaling\n",
            "STEP 2 of 3: CLAHE PRE-PROCESSING COMPLETED\n",
            "1 of 24: TRAINING ON Ben Afflek\n",
            "2 of 24: TRAINING ON Madonna\n",
            "3 of 24: TRAINING ON Jerry Sienfield\n",
            "4 of 24: TRAINING ON Mindy Kaling\n",
            "STEP 3 of 3: TRAINING MODEL COMPLETED\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'done'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NyBRvJAuItE",
        "outputId": "ee28a724-f65f-4eaf-faa0-fa966a3d0cba"
      },
      "source": [
        "%cd drive/My Drive/Periocular_Recognition/Code/dataset1/precognition_ui\n",
        "app = Flask(__name__, template_folder='/content/drive/My Drive/Periocular_Recognition/Code/dataset1/precognition_ui/templates')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template(\"ui.html\")\n",
        "\n",
        "@app.route(\"/ui.html\")\n",
        "def home1():\n",
        "    return render_template(\"ui.html\")\n",
        "\n",
        "@app.route(\"/team.html\")\n",
        "def team():\n",
        "    return render_template(\"team.html\")\n",
        "\n",
        "@app.route(\"/tech.html\")\n",
        "def tech():\n",
        "  return render_template(\"tech.html\")\n",
        "\n",
        "@app.route(\"/about.html\")\n",
        "def about():\n",
        "  return render_template(\"about.html\")\n",
        "\n",
        "@app.route(\"/registration.html\")\n",
        "def reg():\n",
        "  return render_template(\"registration.html\")\n",
        "\n",
        "@app.route(\"/recog.html\")\n",
        "def recog():\n",
        "  return render_template(\"recog.html\")\n",
        "\n",
        "@app.route(\"/pr.html\")\n",
        "def pr():\n",
        "  return render_template(\"pr.html\")\n",
        "\n",
        "@app.route(\"/run.html\", methods=['GET'])\n",
        "def file():\n",
        "  f = request.args.get('filename')\n",
        "  #print(f)\n",
        "  for fm in os.listdir(test_dir):\n",
        "    if fm == f:\n",
        "      present = 1\n",
        "      break\n",
        "    else:\n",
        "      present =0\n",
        "  if present == 1:\n",
        "    fp = os.path.splitext(f)\n",
        "    if fp[1] == \".jpg\" or fp[1]== \".png\" or fp[1]== \".jpeg\":\n",
        "      path = os.path.join(test_dir, f)\n",
        "      #print(path)\n",
        "      name = predict_person(path)\n",
        "      #print(name)\n",
        "      return render_template(\"run.html\", name=name, f=f)\n",
        "    else:\n",
        "      return render_template(\"invfile.html\")\n",
        "  else:\n",
        "    return render_template(\"mul_exist.html\")\n",
        "\n",
        "\n",
        "@app.route(\"/train.html\")\n",
        "def train():\n",
        "  status = create_model()\n",
        "  if status == \"done\":\n",
        "    print(\"\\n\\n\\n\\n\\n----------TRAINING DONE----------/n/n/n/n/n\")\n",
        "  return render_template(\"recog.html\",accuracy=\"\")\n",
        "\n",
        "@app.route(\"/acc.html\")\n",
        "def acc():\n",
        "  #uncomment the below line to render model accuracy in real time\n",
        "  accuracy = get_model_accuracy()\n",
        "  return render_template(\"recog.html\",accuracy=accuracy)\n",
        "app.run()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Periocular_Recognition/Code/dataset1/precognition_ui'\n",
            "/content/drive/My Drive/Periocular_Recognition/Code/dataset1/precognition_ui\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://b200e258412c.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqvg9NQh4QSi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}